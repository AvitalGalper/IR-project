{"cells":[{"cell_type":"markdown","id":"a00e032c","metadata":{"id":"a00e032c"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"]},{"cell_type":"code","execution_count":1,"id":"5ac36d3a","metadata":{"id":"5ac36d3a","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME          PLATFORM  PRIMARY_WORKER_COUNT  SECONDARY_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","cluster-68da  GCE       2                                             RUNNING  us-central1-a\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"markdown","id":"51cf86c5","metadata":{"id":"51cf86c5"},"source":["# Imports & Setup"]},{"cell_type":"code","execution_count":2,"id":"bf199e6a","metadata":{"id":"bf199e6a","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":3,"id":"d8f56ecd","metadata":{"id":"d8f56ecd","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","from google.cloud import storage\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":4,"id":"38a897f2","metadata":{"id":"38a897f2","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Mar  4 15:40 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"]},{"cell_type":"code","execution_count":5,"id":"47900073","metadata":{"id":"47900073","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"]},{"cell_type":"code","execution_count":6,"id":"72bed56b","metadata":{"id":"72bed56b","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-68da-m.c.ir-project-aon.internal:39053\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fc40cc1ae60>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":7,"id":"980e62a5","metadata":{"id":"980e62a5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = 'irprojectaon' \n","full_path = f\"gs://{bucket_name}/\"\n","paths=[]\n","\n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","\n","for b in blobs:\n","    if b.name.endswith('.parquet'):\n","        paths.append(full_path+b.name)"]},{"cell_type":"markdown","id":"cac891c2","metadata":{"id":"cac891c2"},"source":["***GCP setup is complete!*** If you got here without any errors you've earned 10 out of the 35 points of this part."]},{"cell_type":"markdown","id":"582c3f5e","metadata":{"id":"582c3f5e"},"source":["# Building an inverted index"]},{"cell_type":"markdown","id":"481f2044","metadata":{"id":"481f2044"},"source":["Here, we read the entire corpus to an rdd, directly from Google Storage Bucket and use your code from Colab to construct an inverted index."]},{"cell_type":"code","execution_count":8,"id":"e4c523e7","metadata":{"id":"e4c523e7","outputId":"5cfc9631-97c3-4e36-b694-9520de6cbbb8","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# the next three cells are for creating DL dict for the whole corpus and copy it to the bucket\n","parquetFile = spark.read.parquet(*paths)\n","doc_anchor_pairs = parquetFile.select(\"id\", \"anchor_text\").rdd\n","page_pointer_text = doc_anchor_pairs.flatMap(lambda x:x[1]).reduceByKey(lambda x,y:x + '. ' + y)\n","doc_anchor_pairs = page_pointer_text.map(lambda x: Row(anchor_text=x[1], id=x[0]))"]},{"cell_type":"code","execution_count":9,"id":"a8d561ab","metadata":{},"outputs":[],"source":["# english_stopwords = frozenset(stopwords.words('english'))\n","# corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","#                     \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","#                     \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","#                     \"many\", \"however\", \"would\", \"became\"]\n","\n","# all_stopwords = english_stopwords.union(corpus_stopwords)\n","# RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","\n","# def tokenize(text):\n","#     list_of_tokens =  [token.group() for token in RE_WORD.finditer(text.lower()) if token.group() not in all_stopwords]    \n","#     return list_of_tokens"]},{"cell_type":"code","execution_count":10,"id":"MUPFf-WGuEOd","metadata":{"id":"MUPFf-WGuEOd"},"outputs":[],"source":["# DL_dict = doc_text_pairs.map(lambda row: (row[1], len(tokenize(row[0])))).collectAsMap()\n","# with open('DL_big_dict_stopwords_removed.pkl', 'wb') as handle:\n","#    pickle.dump(DL_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":11,"id":"936b7tDtuOs2","metadata":{"id":"936b7tDtuOs2"},"outputs":[],"source":["# DL_dict_src = \"DL_big_dict_stopwords_removed.pkl\"\n","# DL_dict_dst = f'gs://{bucket_name}/{DL_dict_src}'\n","# !gsutil cp $DL_dict_src $DL_dict_dst"]},{"cell_type":"code","execution_count":12,"id":"b7f086c3","metadata":{},"outputs":[],"source":["# print(len(DL_dict.keys()))"]},{"cell_type":"code","execution_count":13,"id":"TRW3DXZ2ukEn","metadata":{"id":"TRW3DXZ2ukEn"},"outputs":[],"source":["# # the next three cells are for creating title dict for the whole corpus and copy it to the bucket\n","# doc_title_pairs_for_dict = parquetFile.select(\"id\", \"title\").rdd\n","# docs_titles_big_dict = doc_title_pairs_for_dict.collectAsMap()\n","# with open('docs_to_title_big_dict.pkl', 'wb') as handle:\n","#    pickle.dump(docs_titles_big_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":14,"id":"O_q2IHUkuzRT","metadata":{"id":"O_q2IHUkuzRT"},"outputs":[],"source":["# index_src_title = \"docs_to_title_big_dict.pkl\"\n","# index_dst_title = f'gs://{bucket_name}/{index_src_title}'\n","# !gsutil cp $index_src_title $index_dst_title"]},{"cell_type":"markdown","id":"0d7e2971","metadata":{"id":"0d7e2971"},"source":["We will count the number of pages to make sure we are looking at the entire corpus. The number of pages should be more than 6M"]},{"cell_type":"code","execution_count":15,"id":"55713560","metadata":{},"outputs":[],"source":["# print(len(docs_titles_big_dict.keys()))"]},{"cell_type":"code","execution_count":16,"id":"82881fbf","metadata":{"id":"82881fbf","outputId":"84bc966d-2932-45ef-aaa4-a91c0559672e"},"outputs":[],"source":["# # Count number of wiki pages\n","# parquetFile.count()"]},{"cell_type":"code","execution_count":17,"id":"iqburEr5v5Zn","metadata":{"id":"iqburEr5v5Zn"},"outputs":[],"source":["# doc_title_pairs = parquetFile.select(\"title\", \"id\").rdd"]},{"cell_type":"markdown","id":"701811af","metadata":{"id":"701811af"},"source":["Let's import the inverted index module. Note that you need to use the staff-provided version called `inverted_index_gcp.py`, which contains helper functions to writing and reading the posting files similar to the Colab version, but with writing done to a Google Cloud Storage bucket."]},{"cell_type":"code","execution_count":18,"id":"121fe102","metadata":{"id":"121fe102","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_gcp.py"]},{"cell_type":"code","execution_count":19,"id":"57c101a8","metadata":{"id":"57c101a8","scrolled":true},"outputs":[],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":20,"id":"c259c402","metadata":{"id":"c259c402"},"outputs":[],"source":["from inverted_index_gcp import InvertedIndex"]},{"cell_type":"markdown","id":"5540c727","metadata":{"id":"5540c727"},"source":["**YOUR TASK (10 POINTS)**: Use your implementation of `word_count`, `reduce_word_counts`, `calculate_df`, and `partition_postings_and_write` functions from Colab to build an inverted index for all of English Wikipedia in under 2 hours.\n","\n","A few notes: \n","1. The number of corpus stopwords below is a bit bigger than the colab version since we are working on the whole corpus and not just on one file.\n","2. You need to slightly modify your implementation of  `partition_postings_and_write` because the signature of `InvertedIndex.write_a_posting_list` has changed and now includes an additional argument called `bucket_name` for the target bucket. See the module for more details.\n","3. You are not allowed to change any of the code not coming from Colab. "]},{"cell_type":"code","execution_count":21,"id":"f3ad8fea","metadata":{"id":"f3ad8fea","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = [\"category\", \"references\", \"also\", \"external\", \"links\", \n","                    \"may\", \"first\", \"see\", \"history\", \"people\", \"one\", \"two\", \n","                    \"part\", \"thumb\", \"including\", \"second\", \"following\", \n","                    \"many\", \"however\", \"would\", \"became\"]\n","\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","\n","def tokenize(text):\n","    list_of_tokens =  [token.group() for token in RE_WORD.finditer(text.lower()) if token.group() not in all_stopwords]    \n","    return list_of_tokens\n","\n","NUM_BUCKETS = 124\n","def token2bucket_id(token):\n","  return int(_hash(token),16) % NUM_BUCKETS\n","\n","def word_count(text, id):\n","  tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","  # YOUR CODE HERE\n","  dic = {}\n","  returnLst = []\n","  for token in tokens:\n","    if token in dic:\n","      changeVal = dic[token]\n","      changeVal += 1\n","      dic[token] = changeVal\n","    else:\n","      if token in all_stopwords:\n","        continue\n","      dic.update({token: 1})\n","  for key in dic:\n","    returnLst.append((key,(id,dic[key])))\n","  return(returnLst)\n","\n","def reduce_word_counts(unsorted_pl):\n","  newLst = {x: 0 for x, _ in unsorted_pl}\n","  for wiki_id, tf in unsorted_pl:\n","      newLst[wiki_id] += tf\n","  Output = list(map(tuple, newLst.items()))\n","  Output.sort(key=lambda a: a[0])\n","  return(Output)\n","\n","def calculate_df(postings):\n","    newRdd = postings.map(lambda x: (x[0], len(x[1])))\n","    return newRdd\n","\n","\n","def partition_postings_and_write(postings):\n","  makeTup = postings.map(lambda x: (token2bucket_id(x[0]),(x[0],x[1])))\n","  checkRdd = makeTup.groupByKey().mapValues(list)\n","  finalRes = checkRdd.map(lambda y: InvertedIndex.write_a_posting_list(y, bucket_name, \"anchor_big_index_with_filter_1\"))\n","  return finalRes"]},{"cell_type":"code","execution_count":22,"id":"55c8764e","metadata":{"id":"55c8764e","nbgrader":{"grade":false,"grade_id":"cell-index_construction","locked":false,"schema_version":3,"solution":true,"task":false},"outputId":"adaf1ea6-e3a0-435b-8b99-ee3b38ca265a"},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/04 16:59:09 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000004 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 16:59:08.933]Container killed on request. Exit code is 143\n","[2024-03-04 16:59:08.934]Container exited with a non-zero exit code 143. \n","[2024-03-04 16:59:08.936]Killed by external signal\n",".\n","24/03/04 16:59:09 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_1709566818322_0003_01_000004 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 16:59:08.933]Container killed on request. Exit code is 143\n","[2024-03-04 16:59:08.934]Container exited with a non-zero exit code 143. \n","[2024-03-04 16:59:08.936]Killed by external signal\n",".\n","24/03/04 16:59:09 ERROR YarnScheduler: Lost executor 3 on cluster-68da-w-1.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000004 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 16:59:08.933]Container killed on request. Exit code is 143\n","[2024-03-04 16:59:08.934]Container exited with a non-zero exit code 143. \n","[2024-03-04 16:59:08.936]Killed by external signal\n",".\n","24/03/04 16:59:09 WARN TaskSetManager: Lost task 40.0 in stage 2.0 (TID 101) (cluster-68da-w-1.c.ir-project-aon.internal executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000004 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 16:59:08.933]Container killed on request. Exit code is 143\n","[2024-03-04 16:59:08.934]Container exited with a non-zero exit code 143. \n","[2024-03-04 16:59:08.936]Killed by external signal\n",".\n","24/03/04 17:01:22 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000001 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:22.655]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:22.656]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:22.657]Killed by external signal\n",".\n","24/03/04 17:01:22 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1709566818322_0003_01_000001 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:22.655]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:22.656]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:22.657]Killed by external signal\n",".\n","24/03/04 17:01:22 ERROR YarnScheduler: Lost executor 1 on cluster-68da-w-1.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000001 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:22.655]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:22.656]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:22.657]Killed by external signal\n",".\n","24/03/04 17:01:22 WARN TaskSetManager: Lost task 53.0 in stage 2.0 (TID 115) (cluster-68da-w-1.c.ir-project-aon.internal executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000001 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:22.655]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:22.656]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:22.657]Killed by external signal\n",".\n","24/03/04 17:01:26 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000005 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:25.917]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:25.917]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:25.917]Killed by external signal\n",".\n","24/03/04 17:01:26 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_1709566818322_0003_01_000005 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:25.917]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:25.917]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:25.917]Killed by external signal\n",".\n","24/03/04 17:01:26 ERROR YarnScheduler: Lost executor 4 on cluster-68da-w-0.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000005 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:25.917]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:25.917]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:25.917]Killed by external signal\n",".\n","24/03/04 17:01:26 WARN TaskSetManager: Lost task 52.0 in stage 2.0 (TID 114) (cluster-68da-w-0.c.ir-project-aon.internal executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000005 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:01:25.917]Container killed on request. Exit code is 143\n","[2024-03-04 17:01:25.917]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:01:25.917]Killed by external signal\n",".\n","24/03/04 17:03:24 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000002 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:03:23.860]Container killed on request. Exit code is 143\n","[2024-03-04 17:03:23.860]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:03:23.860]Killed by external signal\n",".\n","24/03/04 17:03:24 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1709566818322_0003_01_000002 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:03:23.860]Container killed on request. Exit code is 143\n","[2024-03-04 17:03:23.860]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:03:23.860]Killed by external signal\n",".\n","24/03/04 17:03:24 ERROR YarnScheduler: Lost executor 2 on cluster-68da-w-0.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000002 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:03:23.860]Container killed on request. Exit code is 143\n","[2024-03-04 17:03:23.860]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:03:23.860]Killed by external signal\n",".\n","24/03/04 17:03:24 WARN TaskSetManager: Lost task 57.0 in stage 2.0 (TID 121) (cluster-68da-w-0.c.ir-project-aon.internal executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000002 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:03:23.860]Container killed on request. Exit code is 143\n","[2024-03-04 17:03:23.860]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:03:23.860]Killed by external signal\n",".\n","24/03/04 17:05:36 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000006 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:05:35.877]Container killed on request. Exit code is 143\n","[2024-03-04 17:05:35.877]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:05:35.877]Killed by external signal\n",".\n","24/03/04 17:05:36 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_1709566818322_0003_01_000006 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:05:35.877]Container killed on request. Exit code is 143\n","[2024-03-04 17:05:35.877]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:05:35.877]Killed by external signal\n",".\n","24/03/04 17:05:36 ERROR YarnScheduler: Lost executor 5 on cluster-68da-w-1.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000006 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:05:35.877]Container killed on request. Exit code is 143\n","[2024-03-04 17:05:35.877]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:05:35.877]Killed by external signal\n",".\n","24/03/04 17:05:36 WARN TaskSetManager: Lost task 83.0 in stage 2.0 (TID 148) (cluster-68da-w-1.c.ir-project-aon.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000006 on host: cluster-68da-w-1.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:05:35.877]Container killed on request. Exit code is 143\n","[2024-03-04 17:05:35.877]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:05:35.877]Killed by external signal\n",".\n","24/03/04 17:10:24 WARN YarnAllocator: Container from a bad node: container_1709566818322_0003_01_000009 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:10:23.975]Container killed on request. Exit code is 143\n","[2024-03-04 17:10:23.976]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:10:23.981]Killed by external signal\n",".\n","24/03/04 17:10:24 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 8 for reason Container from a bad node: container_1709566818322_0003_01_000009 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:10:23.975]Container killed on request. Exit code is 143\n","[2024-03-04 17:10:23.976]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:10:23.981]Killed by external signal\n",".\n","24/03/04 17:10:24 ERROR YarnScheduler: Lost executor 8 on cluster-68da-w-0.c.ir-project-aon.internal: Container from a bad node: container_1709566818322_0003_01_000009 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:10:23.975]Container killed on request. Exit code is 143\n","[2024-03-04 17:10:23.976]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:10:23.981]Killed by external signal\n",".\n","24/03/04 17:10:24 WARN TaskSetManager: Lost task 81.0 in stage 3.0 (TID 272) (cluster-68da-w-0.c.ir-project-aon.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709566818322_0003_01_000009 on host: cluster-68da-w-0.c.ir-project-aon.internal. Exit status: 143. Diagnostics: [2024-03-04 17:10:23.975]Container killed on request. Exit code is 143\n","[2024-03-04 17:10:23.976]Container exited with a non-zero exit code 143. \n","[2024-03-04 17:10:23.981]Killed by external signal\n",".\n","                                                                                \r"]}],"source":["# time the index creation time\n","# t_start = time()\n","# word counts map\n","word_counts = doc_anchor_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n","postings = word_counts.groupByKey().mapValues(reduce_word_counts)\n","# filtering postings and calculate df\n","postings_filtered = postings.map(lambda x: (x[0], [(doc_id, tf) for doc_id, tf in x[1] if tf > 1]))\n","# postings_filtered = postings.filter(lambda x: len(x[1])>50)\n","w2df = calculate_df(postings_filtered)\n","w2df_dict = w2df.collectAsMap()\n","# partition posting lists and write out\n","_ = partition_postings_and_write(postings_filtered).collect()\n","# index_const_time = time() - t_start"]},{"cell_type":"code","execution_count":23,"id":"3dbc0e14","metadata":{"id":"3dbc0e14","nbgrader":{"grade":true,"grade_id":"cell-index_const_time","locked":true,"points":10,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# test index construction time\n","# assert index_const_time < 60*120"]},{"cell_type":"code","execution_count":24,"id":"ab3296f4","metadata":{"id":"ab3296f4","nbgrader":{"grade":true,"grade_id":"collect-posting","locked":true,"points":0,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["# collect all posting lists locations into one super-set\n","super_posting_locs = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='postings_gcp_anchor_big_index_with_filter_1'):\n","  if not blob.name.endswith(\"pickle\"):\n","    continue\n","  with blob.open(\"rb\") as f:\n","    posting_locs = pickle.load(f)\n","    for k, v in posting_locs.items():\n","      super_posting_locs[k].extend(v)"]},{"cell_type":"markdown","id":"f6f66e3a","metadata":{"id":"f6f66e3a"},"source":["Putting it all together"]},{"cell_type":"code","execution_count":25,"id":"a5d2cfb6","metadata":{"id":"a5d2cfb6","outputId":"8231b5a1-8f82-4f9d-97d4-d91d2939544b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying file://anchor_big_index_with_filter_1.pkl [Content-Type=application/octet-stream]...\n","- [1 files][ 85.0 MiB/ 85.0 MiB]                                                \n","Operation completed over 1 objects/85.0 MiB.                                     \n"]}],"source":["# Create inverted index instance\n","inverted = InvertedIndex()\n","# Adding the posting locations dictionary to the inverted index\n","inverted.posting_locs = super_posting_locs\n","# Add the token - df dictionary to the inverted index\n","inverted.df = w2df_dict\n","# write the global stats out\n","inverted.write_index('.', 'anchor_big_index_with_filter_1')\n","# upload to gs\n","index_src = \"anchor_big_index_with_filter_1.pkl\"\n","index_dst = f'gs://{bucket_name}/postings_gcp_anchor_big_index_with_filter_1/{index_src}'\n","!gsutil cp $index_src $index_dst"]},{"cell_type":"code","execution_count":26,"id":"8f880d59","metadata":{"id":"8f880d59","nbgrader":{"grade":false,"grade_id":"cell-index_dst_size","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"6c376cce-cc0c-47a6-f34d-57377c23fda4"},"outputs":[{"name":"stdout","output_type":"stream","text":["    85 MiB  2024-03-04T17:15:25Z  gs://irprojectaon/postings_gcp_anchor_big_index_with_filter_1/anchor_big_index_with_filter_1.pkl\r\n","TOTAL: 1 objects, 89125134 bytes (85 MiB)\r\n"]}],"source":["!gsutil ls -lh $index_dst"]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
